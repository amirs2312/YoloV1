{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Basics to YOLO-V1\n",
    "\n",
    "- YOLO was trained on the PASCAL VOC dataset (20 classes). This is a bit outdated, COCO is more popular nowadays. \n",
    "\n",
    "- The goal is to output bounding boxes on detected objects.\n",
    "- Split grid into a $S.S$ grid. Giving $S^2$ cells in the image.\n",
    "- Each cell will output a prediction with a corresponding bounding box.\n",
    "\n",
    "\n",
    "\n",
    "An object may appear in multiple cells, ie its body lies inbetween cells. We don't want to output duplicate boxes for the object though, so we say that the cell responsible for ouputting the bounding box on a detected object is the one which contains the objects midpoint (mp). Each output will be relative to the cell, ie each bounding box will be expressed in the form $(x, y, w, h)$ or $(x_{mp}, y_{mp}, width, height)$. These are all relative to a given cell, ie normalised between 0 and 1. Note that width and height can be greater than 1 if the object exists outside of the cell also. \n",
    "\n",
    "\n",
    "- Each cell can only detect one object.\n",
    "\n",
    "- The target shape will be $(S.S.25)$. $SxS$ indicates that for each cell there will be a length 25 vector, where the first 20 correspond to the class probabilities, the next 1 corresponds to the probability score, and the remaining 4 correspond to the bounding boxes.\n",
    "- The prediction shape will be $(S.S.30)$, the extra 5 is to accomodate another porobability score and boudning box prediction. The hope is that these two boxes will get good at different things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import Linear\n",
    "import torchvision\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        super(CNNBlock, self).__init__()\n",
    "        \n",
    "        self.conv       = nn.Conv2d(in_channels, out_channels, bias=False, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.batchnorm  = nn.BatchNorm2d(out_channels) # Batch norm wasnt actually invented when Yolo droppped but eh\n",
    "        self.leaky_relu = nn.LeakyReLU(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "class Yolov1(nn.Module):\n",
    "    def __init__(self, split_size, num_boxes, num_classes, in_channels=3):\n",
    "        super(Yolov1, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.darknet = self.create_conv_layers()\n",
    "        self.fc = self.create_fc(split_size=split_size, num_boxes=num_boxes, num_classes=num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.darknet(x)\n",
    "        x = torch.flatten(x, start_dim=1) # LOOK INTO THIS\n",
    "        return self.fc(x)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # The convolutional layers of Yolo V1. This isnt the cleanest, or least verbose way to implement this, but its a decent way to learn the architecture\n",
    "    def create_conv_layers(self):\n",
    "\n",
    "        layers = []\n",
    "        in_channels = self.in_channels\n",
    "\n",
    "        layers.append(CNNBlock(in_channels=in_channels, out_channels=64, kernel_size=7, stride=2, padding=3))\n",
    "\n",
    "        layers.append(MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "\n",
    "\n",
    "        layers.append(CNNBlock(in_channels=64, out_channels=192, kernel_size=3, stride=1, padding=1))\n",
    "\n",
    "        layers.append(MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        layers.append(CNNBlock(in_channels=192, out_channels=128, kernel_size=1, stride=1, padding=0))\n",
    "\n",
    "        layers.append(CNNBlock(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1))\n",
    "\n",
    "        layers.append(CNNBlock(in_channels=256, out_channels=256, kernel_size=1, stride=1, padding=0))\n",
    "\n",
    "        layers.append(CNNBlock(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1))\n",
    "\n",
    "        layers.append(MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "\n",
    "        # Note this is NOT how you should handle repeated layers, it only works in this case since the output channel\n",
    "        # dimension matches the input channel dimension\n",
    "        for i in range(4):\n",
    "\n",
    "            layers.append(CNNBlock(in_channels=512, out_channels=256, kernel_size=1, stride=1, padding=0))\n",
    "\n",
    "            layers.append(CNNBlock(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1))\n",
    "\n",
    "        layers.append(CNNBlock(in_channels=512, out_channels=512, kernel_size=1, stride=1, padding=0))\n",
    "\n",
    "        layers.append(CNNBlock(in_channels=512, out_channels=1024, kernel_size=3, stride=1, padding=1))\n",
    "\n",
    "        layers.append(MaxPool2d(kernel_size=2, stride=2)) # This reduces the tensor to a 7x7x channels grid\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(2):\n",
    "\n",
    "            layers.append(CNNBlock(in_channels=1024, out_channels=512, kernel_size=1, stride=1, padding=0))\n",
    "\n",
    "            layers.append(CNNBlock(in_channels=512, out_channels=1024, kernel_size=3, stride=1, padding=1))\n",
    "\n",
    "        layers.append(CNNBlock(in_channels=1024, out_channels=1024, kernel_size=3, stride=1, padding=1))\n",
    "\n",
    "        layers.append(CNNBlock(in_channels=1024, out_channels=1024, kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        layers.append(CNNBlock(in_channels=1024, out_channels=1024, kernel_size=3, stride=1, padding=1))\n",
    "\n",
    "        layers.append(CNNBlock(in_channels=1024, out_channels=1024, kernel_size=3, stride=1, padding=1))\n",
    "\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def create_fc(self, split_size, num_boxes, num_classes):\n",
    "        S, B, C = split_size, num_boxes, num_classes\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        #layers.append(nn.Flatten())\n",
    "\n",
    "        layers.append(nn.Linear(1024*S*S, 2048)) # Original paper has 4096 but simplify for our testing\n",
    "\n",
    "        layers.append(nn.Dropout(0.5))\n",
    "\n",
    "        layers.append(nn.LeakyReLU(0.1))\n",
    "\n",
    "        layers.append(Linear(2048, S*S*(C+B*5)))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1470])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# pass a tensor thorugh the model to check if it works\n",
    "def test(split_size = 7, num_boxes = 2, num_classes = 20):\n",
    "    model = Yolov1(split_size, num_boxes, num_classes)\n",
    "    x = torch.randn((3,3, 448, 448))\n",
    "\n",
    "    print(model(x).shape)\n",
    "\n",
    "\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QRL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
